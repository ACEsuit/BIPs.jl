{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIP Framework tuning example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is **NOT** taken from the original paper, but it is a way to tune the parameters of the BIP Framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"..\")\n",
    "using BIPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "using Pkg.Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets begin by bringing in the dataset. It contains tree splits:\n",
    "* **train**: the training set with 1M jets\n",
    "* **validation**: the validation set with 400k jets\n",
    "\n",
    "And of course later we will use the **test** set with other 400k jets to report the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../../DataLake/raw\"\n",
    "train_data_path = dataset_path*\"/train.h5\"\n",
    "val_data_path = dataset_path*\"/val.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data\n",
    "\n",
    "In order to read the datasets, we call the `read_dataset` function:\n",
    "to read the TopQuark format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_jets, train_labels = BIPs.read_data(\"TQ\", train_data_path)\n",
    "train_labels = [reinterpret(Bool, b == 1.0) for b in train_labels]\n",
    "print(\"Number of entries in the training data: \", length(train_jets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_jets, val_labels = BIPs.read_data(\"TQ\", val_data_path)\n",
    "val_labels = [reinterpret(Bool, b == 1.0) for b in val_labels]\n",
    "print(\"Number of entries in the validation data: \", length(val_jets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets examine how one of the jets looks like, each one of the entries is one detected particle's four momentum $(E, p_x, p_y, p_z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However,in order to compute the embeddings, it is necesary to convert the jets to a format that can be used by the framework. The function `data2hyp` allows to convert each detected four momentum to the jet basis, a.k.a $(\\tilde p_T, \\cos(\\theta), \\sin(\\theta), \\tilde y, E_T)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transf_jets = data2hyp(train_jets)\n",
    "val_transf_jets = data2hyp(val_jets)\n",
    "println(\"Transformed jets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the jets are converted to the jet basis, it is moment to embed the model using the *Invariant Polynomials*. \n",
    "\n",
    "The function `build_ip` allocates efficiently the sparse basis, while the `bip_data` computes the invariant representation of each one of the jets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_bip, specs = build_ip(order=4, levels=8)\n",
    "    \n",
    "function bip_data(dataset_jets)\n",
    "    storage = zeros(length(dataset_jets), length(specs))\n",
    "    for i = 1:length(dataset_jets)\n",
    "        storage[i, :] = f_bip(dataset_jets[i])\n",
    "    end\n",
    "    storage[:, 2:end]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedded_jets = bip_data(train_transf_jets)\n",
    "println(\"Embedded train jets correclty\")\n",
    "val_embedded_jets = bip_data(val_transf_jets)\n",
    "println(\"Embedded test jets correclty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embeddings are now created for the dataset. From this point on, the classification itself is absolutelly versatile. For this specific example we will use the out-of-the box classifier `sklearn.linear_model.HistGradientBoostingClassifier` that bines the data and then applies a grandient boosted trees algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets fit a simple model to the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "@pyimport sklearn.neural_network as sk_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = sk_nn.MLPClassifier(verbose=true,max_iter=2000, njobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = Dict(\n",
    "    \"hidden_layer_sizes\"  => [ (100,), (50,50,50), (200,100,50,25), (100,50)],\n",
    "    \"activation\"  => [\"tanh\", \"relu\", \"logistic\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pyimport sklearn.model_selection as sk_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sk_ms.GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(train_embedded_jets, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lest test how we do performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understanad the framework, lets see how our model performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = \"../../../DataLake/raw/test.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_jets, test_labels = BIPs.read_data(\"TQ\", test_data_path)\n",
    "test_labels = [reinterpret(Bool, b == 1.0) for b in test_labels]\n",
    "test_transf_jets = data2hyp(test_jets)\n",
    "test_embedded_jets = bip_data(test_transf_jets)\n",
    "print(\"Embedded test jets correclty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = clf.score(test_embedded_jets, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "test_probas = clf.predict_proba(test_embedded_jets)\n",
    "bkg_index = [label==false for label in test_labels]\n",
    "Plots.histogram(test_probas[:, 2][test_labels], color=\"Blue\", label=\"Top Jets\", xlabel=\"Model's Output Probability\", ylabel=\"Number of Jets\")\n",
    "Plots.histogram!(test_probas[:, 2][bkg_index], color=\"Red\", label=\"QCD Jets\", title=\"Probability Scores\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f075184c5ef2f0b32d809a510d5efd6bb855cd1f11e474e44795b0201961dbbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
